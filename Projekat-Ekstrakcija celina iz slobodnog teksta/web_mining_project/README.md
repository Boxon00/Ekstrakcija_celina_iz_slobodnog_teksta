# ğŸ§  Projekat: Ekstrakcija celina iz slobodnog teksta

## ğŸ“˜ Opis projekta  
Ovaj projekat ima za cilj **automatsku ekstrakciju tematskih celina iz slobodnog teksta** koriÅ¡Ä‡enjem kombinacije modernih **NLP (Natural Language Processing)** tehnika.  
Projekat koristi **BERT NER model**, **Sentence-BERT embeddings**, **K-Means klasterovanje**, **TF-IDF analizu kljuÄnih reÄi**, i **vizualizacije** radi prikaza strukture teksta.

ZamiÅ¡ljen je kao praktiÄan primer **web mining** sistema koji moÅ¾e pomoÄ‡i u analizi velikih koliÄina teksta â€“ poput novinskih Älanaka, blogova ili dokumenata.

---

## âš™ï¸ Funkcionalnosti  

âœ… Automatsko prikupljanje tekstova sa BBC RSS izvora  
âœ… Prepoznavanje imenovanih entiteta pomoÄ‡u BERT NER modela  
âœ… Kreiranje Sentence-BERT vektorskih reprezentacija reÄenica  
âœ… Automatsko klasterovanje teksta pomoÄ‡u K-Means algoritma  
âœ… Validacija i evaluacija klastera  
âœ… Generisanje kljuÄnih reÄi koriÅ¡Ä‡enjem TF-IDF algoritma  
âœ… Vizualizacija rezultata:
- PCA graf klastera  
- WordCloud svake teme  
- Graf povezanosti entiteta  

---
## ğŸ’» Testiranje na Google Colab-u

Pre nego Å¡to je projekat finalizovan i pripremljen za lokalno pokretanje, **ceo razvoj i testiranje je izvrÅ¡eno na Google Colab-u**.  

Razlozi za koriÅ¡Ä‡enje Colab-a:
- **Brzo eksperimentisanje** sa velikim NLP modelima (BERT, Sentence-BERT) bez potrebe za lokalnom GPU infrastrukturom.  
- **Jednostavna instalacija zavisnosti** preko `pip` komandi direktno u Colab okruÅ¾enju.  
- **Interaktivna provera rezultata**, vizualizacija i analiza podataka, gde su grafici i WordCloud-ovi mogli odmah da se prikaÅ¾u u notebook-u.  

Å ta je testirano:
1. **Scraping i prikupljanje podataka** sa BBC RSS feed-a.  
2. **NER ekstrakcija** imenovanih entiteta pomoÄ‡u BERT modela.  
3. **Sentence-BERT embeddings** i kreiranje vektorskih reprezentacija reÄenica.  
4. **K-Means klasterovanje** i odreÄ‘ivanje optimalnog broja klastera.  
5. **Validacija klastera** i generisanje TF-IDF kljuÄnih reÄi.  
6. **Vizualizacije**: PCA dijagrami, WordCloud za teme i graf povezanosti entiteta.  

Nakon Å¡to je ceo pipeline uspeÅ¡no testiran i validiran u Colab-u, projekat je prebaÄen i pripremljen za **lokalno pokretanje** pomoÄ‡u `main.py` i folder strukture opisane u ovom README-u.

> Google Colab je posluÅ¾io kao idealno testno okruÅ¾enje za razvoj, jer je omoguÄ‡io brzu iteraciju, vizualnu proveru rezultata i rad sa zahtevnijim NLP modelima bez lokalnih ograniÄenja.

## ğŸ§© Struktura projekta  

```
web_mining_project/
â”‚
â”œâ”€ modules/                     # Funkcionalni delovi projekta
â”‚   â”œâ”€ __init__.py
â”‚   â”œâ”€ scraper.py               # Prikupljanje vesti sa BBC RSS feed-a
â”‚   â”œâ”€ ner_bert.py              # BERT NER pipeline i ekstrakcija entiteta
â”‚   â”œâ”€ embeddings.py            # Sentence-BERT embeddings
â”‚   â”œâ”€ clustering.py            # K-Means klasterovanje i optimalan broj klastera
â”‚   â”œâ”€ validation.py            # Validacija i evaluacija klastera
â”‚   â”œâ”€ tfidf_keywords.py        # TF-IDF analiza kljuÄnih reÄi
â”‚   â”œâ”€ visualization/           # Podfolder za sve vizualizacije
â”‚   â”‚   â”œâ”€ __init__.py
â”‚   â”‚   â”œâ”€ pca_plot.py          # PCA dijagram klastera
â”‚   â”‚   â”œâ”€ wordcloud_plot.py    # WordCloud prikaz tema
â”‚   â”‚   â””â”€ network_graph.py     # Graf povezanosti entiteta
â”‚
â”œâ”€ results/                     # Folder gde se automatski Äuvaju slike i grafici
â”‚
â”œâ”€ main.py                      # Glavni fajl koji pokreÄ‡e ceo projekat
â”œâ”€ README.md                    # Opis projekta
â””â”€ requirements.txt             # Lista potrebnih Python biblioteka

```

## ğŸ› ï¸ Instalacija i pokretanje  

1. **Kloniraj repozitorijum:**
   ```bash
   git clone https://github.com/Boxon00/Ekstrakcija_celina_iz_slobodnog_teksta.git
   cd Ekstrakcija_celina_iz_slobodnog_teksta/web_mining_project
   ```

2. **(Opcionalno) Kreiraj virtuelno okruÅ¾enje:**
   ```bash
   python -m venv venv
   source venv/bin/activate      # Linux/Mac
   venv\Scripts\activate         # Windows
   ```

3. **Instaliraj zavisnosti:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Pokreni projekat:**
   ```bash
   python main.py
   ```

---

## ğŸ“Š Rezultati i vizualizacije  

Projekat generiÅ¡e sledeÄ‡e vizualizacije:

- ğŸ§© **pca_plot.png** â€“ prikaz klastera pomoÄ‡u PCA dimenzionalne redukcije  
- â˜ï¸ **wordclouds.png** â€“ WordCloud prikaz kljuÄnih reÄi za svaku temu  
- ğŸ”— **entity_graph.png** â€“ graf povezanosti entiteta detektovanih BERT modelom

Sve slike se automatski Äuvaju u folderu `results/`.

---

## ğŸ§  KoriÅ¡Ä‡ene tehnologije  

- **Python 3.10+**  
- **Transformers (Hugging Face)** â€“ BERT modeli  
- **SentenceTransformers** â€“ Sentence-BERT embeddings  
- **Scikit-learn** â€“ KMeans, PCA i evaluacija  
- **Matplotlib / Seaborn** â€“ Vizualizacije  
- **WordCloud** â€“ Generisanje oblaka reÄi  
- **Requests / Feedparser** â€“ Prikupljanje tekstova sa interneta  

---

## ğŸ§¾ Napomena  

Projekat je izraÄ‘en kao edukativni primer **NLP analize teksta** i demonstracija procesa **ekstrakcije tematskih celina**.  
MoÅ¾e posluÅ¾iti kao osnov za dalji razvoj alata za analizu novinskih Älanaka, tekstova sa druÅ¡tvenih mreÅ¾a ili dokumenata.

---

## ğŸ“š ZakljuÄak  

Ovaj projekat uspeÅ¡no povezuje viÅ¡e faza obrade prirodnog jezika â€” od prikupljanja i obrade teksta, preko ekstrakcije entiteta i vektorizacije reÄenica, do klasterovanja i vizuelne prezentacije rezultata.  
Kroz upotrebu modernih modela kao Å¡to su **BERT** i **Sentence-BERT**, omoguÄ‡eno je automatsko prepoznavanje tematskih celina i kljuÄnih informacija.  
ReÅ¡enje moÅ¾e biti osnova za razvoj inteligentnih sistema za **analizu teksta, sumarizaciju sadrÅ¾aja** i **istraÅ¾ivaÄke projekte u oblasti NLP-a**.

---

## ğŸ‘¨â€ğŸ’» Autor  

**Bojan [Boxon00]**  
ğŸ“‚ GitHub: [https://github.com/Boxon00](https://github.com/Boxon00)