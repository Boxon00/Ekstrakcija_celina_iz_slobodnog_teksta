# ğŸ§  Ekstrakcija celina iz slobodnog teksta

Ovaj projekat predstavlja **kompletnu implementaciju NLP (Natural Language Processing)** sistema koji automatski analizira slobodan tekst, pronalazi **entitete (osobe, organizacije, lokacije, pojmove)**, zatim pomoÄ‡u **Sentence-BERT** modela izraÄunava semantiÄke sliÄnosti izmeÄ‘u reÄenica i grupiÅ¡e ih u **tematske celine** (klastere).

Na kraju, rezultati se **vizualizuju** kroz viÅ¡e grafiÄkih prikaza: PCA dijagram, WordCloud prikaz i graf povezanosti entiteta.

Projekat je razvijen u **Python-u**, u okruÅ¾enju **Visual Studio Code** (ili Google Colab) i koristi napredne alate iz oblasti maÅ¡inskog uÄenja, obrade prirodnog jezika i vizualizacije podataka.

---

## ğŸ¯ Cilj projekta

Cilj ovog projekta je da prikaÅ¾e kako se iz sirovog slobodnog teksta mogu **automatski izdvojiti tematske celine** pomoÄ‡u kombinacije:
- BERT modela za ekstrakciju entiteta (NER),
- Sentence-BERT embeddings za semantiÄko razumevanje reÄenica,
- KMeans algoritma za klasterovanje,
- TF-IDF analize za izdvajanje kljuÄnih reÄi,
- i vizualizacija koje olakÅ¡avaju interpretaciju rezultata.

Ovakav sistem moÅ¾e biti osnova za:
- automatsku sumarizaciju vesti,  
- tematsko grupisanje dokumenata,  
- prepoznavanje trendova u tekstualnim podacima,  
- analizu sadrÅ¾aja iz druÅ¡tvenih mreÅ¾a ili RSS feedova.

---

## ğŸ§© KoriÅ¡Ä‡ene tehnologije i biblioteke

| Kategorija | Biblioteke / Alati | Opis |
|-------------|--------------------|-------|
| **NLP modeli** | `transformers`, `torch`, `sentence-transformers` | BERT modeli za NER i Sentence Embeddings |
| **Obrada podataka** | `scikit-learn`, `numpy`, `pandas` | Analiza, klasterovanje i evaluacija |
| **Web scraping** | `feedparser`, `requests`, `beautifulsoup4` | Prikupljanje tekstova sa BBC RSS feed-a |
| **Vizualizacija** | `matplotlib`, `seaborn`, `wordcloud`, `networkx` | Kreiranje grafiÄkih prikaza rezultata |
| **Razvojno okruÅ¾enje** | `Visual Studio Code`, `Google Colab` | MoguÄ‡nost pokretanja lokalno i online |

---

## ğŸ“ Struktura projekta

web_mining_project/
â”‚
â”œâ”€ modules/ # Glavni direktorijum sa funkcionalnim modulima
â”‚ â”œâ”€ init.py
â”‚ â”œâ”€ scraper.py # Prikupljanje tekstova sa BBC News RSS feeda
â”‚ â”œâ”€ ner_bert.py # Named Entity Recognition (BERT)
â”‚ â”œâ”€ embeddings.py # Kreiranje Sentence-BERT embeddings
â”‚ â”œâ”€ clustering.py # Klasterovanje pomoÄ‡u KMeans i izbor optimalnog K
â”‚ â”œâ”€ validation.py # Validacija rezultata (poklapanje klastera)
â”‚ â”œâ”€ tfidf_keywords.py # Analiza kljuÄnih reÄi pomoÄ‡u TF-IDF metode
â”‚ â”‚
â”‚ â””â”€ visualization/ # Vizualni prikazi rezultata
â”‚ â”œâ”€ init.py
â”‚ â”œâ”€ pca_plot.py # PCA prikaz klastera (2D redukcija)
â”‚ â”œâ”€ wordcloud_plot.py # WordCloud prikaz po klasterima
â”‚ â””â”€ network_graph.py # Graf povezanosti entiteta
â”œâ”€ results/ # Folder gde se automatski Äuvaju slike (grafici)
â”œâ”€ main.py # Glavni fajl koji pokreÄ‡e sve module
â”œâ”€ README.md
â””â”€ requirements.txt # Lista svih potrebnih biblioteka

---

## âš™ï¸ Instalacija i pokretanje

### 1ï¸âƒ£ Kloniranje repozitorijuma
```bash
git clone https://github.com/Boxon00/Ekstrakcija_celina_iz_slobodnog_teksta.git
cd Ekstrakcija_celina_iz_slobodnog_teksta/web_mining_project
2ï¸âƒ£ Instalacija potrebnih biblioteka
pip install -r requirements.txt
3ï¸âƒ£ Pokretanje projekta
python main.py

ğŸ”„ Tok obrade podataka
ğŸ”¹ 1. Prikupljanje tekstova (scraper.py)

Sistem koristi BBC RSS feed i automatski preuzima najnovije vesti.
Ukoliko nema internet konekcije, koristi se demo skup reÄenica sa tehnoloÅ¡kim vestima.

ğŸ”¹ 2. Prepoznavanje entiteta (ner_bert.py)

Koristi se BERT model (dbmdz/bert-large-cased-finetuned-conll03-english) za NER (Named Entity Recognition).
Model detektuje entitete tipa:

PER (osobe),

ORG (organizacije),

LOC (lokacije),

MISC (ostali pojmovi).

ğŸ”¹ 3. Kreiranje embeddings (embeddings.py)

Za svaku reÄenicu se raÄuna Sentence-BERT embedding pomoÄ‡u modela 'all-MiniLM-L6-v2'.
Ovi vektori predstavljaju semantiÄko znaÄenje reÄenica i koriste se za klasterovanje.

ğŸ”¹ 4. Klasterovanje (clustering.py)

KoriÅ¡Ä‡enjem KMeans algoritma, reÄenice se grupiÅ¡u u tematske celine.
Funkcija find_optimal_k() pronalazi najbolji broj klastera pomoÄ‡u silhouette score metrika.

ğŸ”¹ 5. Validacija (validation.py)

Proverava se da li su sve reÄenice taÄno rasporeÄ‘ene po klasterima bez duplikata ili preklapanja.

ğŸ”¹ 6. TF-IDF analiza (tfidf_keywords.py)

Za svaku celinu se izdvajaju kljuÄne reÄi na osnovu vaÅ¾nosti (TF-IDF).

ğŸ”¹ 7. Vizualizacije (visualization/)

Sistem generiÅ¡e tri vizualna prikaza:

PCA dijagram klastera (pca_plot.py)

WordCloud prikaz po klasterima (wordcloud_plot.py)

Graf povezanosti entiteta (network_graph.py)

Sve slike se automatski Äuvaju u results/ folderu:

pca_plot.png

wordclouds.png

entity_graph.png

## ğŸ§  Arhitektura projekta

Tekst (RSS Feed)
     â”‚
     â–¼
[ BERT NER ] â†’ Ekstrakcija entiteta
     â”‚
     â–¼
[ Sentence-BERT ] â†’ Embeddings reÄenica
     â”‚
     â–¼
[ KMeans klasterovanje ]
     â”‚
     â”œâ”€â”€ TF-IDF analiza (kljuÄne reÄi)
     â”œâ”€â”€ Validacija (duplikati, preklapanja)
     â””â”€â”€ Vizualizacije (PCA, WordCloud, NetworkX)

## ğŸ“˜ Potencijalne primene

Automatizovana klasifikacija vesti po temama

Sumarizacija dokumenata i tekstova

Prepoznavanje odnosa izmeÄ‘u entiteta

Tematska analiza postova, Älanaka i foruma

Generisanje znanja iz nestrukturisanih izvora podataka

## ğŸ ZakljuÄak

Projekat "Ekstrakcija celina iz slobodnog teksta" prikazuje napredan pristup obradi prirodnog jezika i semantiÄkom grupisanju reÄenica.
Kombinuje viÅ¡e tehnika â€” od web scrapinga i maÅ¡inskog uÄenja do vizualizacije i validacije rezultata.

Struktura projekta, modularnost i Äitljivost koda omoguÄ‡avaju lako proÅ¡irenje sistema â€” npr. za srpski jezik, dodatne izvore teksta ili druge NLP zadatke.
